<div>
<h2>&#30446;&#24405;</h2>
<div>
<ul>
<li><a href="http://www.zmonster.me#orgc9e33e4" rel="noopener noreferrer" target="_blank">&#22522;&#30784;&#27169;&#22359;&#26500;&#25104;</a></li>
<li><a href="http://www.zmonster.me#org08971c3" rel="noopener noreferrer" target="_blank">&#20854;&#20182;</a></li>
</ul>
</div>
</div>

<p>
&#36825;&#20004;&#21608;&#31616;&#21333;&#30475;&#20102;&#19979; <a href="http://pytorch.org/" rel="noopener noreferrer" target="_blank">pytorch</a>&#65292;&#34429;&#28982;&#35828;&#36824;&#27809;&#26377;&#38750;&#24120;&#31995;&#32479;&#30340;&#12289;&#20840;&#26041;&#38754;&#30340;&#35748;&#35782;&#65292;&#20294;&#22993;&#19988;&#24635;&#32467;&#19968;&#19979;&#22909;&#20102;&#12290;
</p>

<div>
<h2>&#22522;&#30784;&#27169;&#22359;&#26500;&#25104;</h2>
<div>
<p>
&#26368;&#26680;&#24515;&#30340;&#27169;&#22411;&#32452;&#20214;&#37117;&#22312; torch.nn &#36825;&#20010;&#27169;&#22359;&#37324;&#65292;&#36825;&#20010;&#27169;&#22359;&#37324;&#21253;&#21547;&#20102;
</p>
<ul>
<li>&#19981;&#21516;&#31867;&#22411;&#30340;&#32593;&#32476;&#32467;&#26500;&#65292;&#22914;&#65306;Embedding, LSTM, Conv1d, MaxPool1d, Linear</li>
<li>&#19981;&#21516;&#31867;&#22411;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#22914;&#65306;RELU, SELU, Sigmoid, Tanh</li>
<li>&#19981;&#21516;&#31867;&#22411;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#22914;&#65306;CrossEntropyLoss, MSELoss, HingeEmbeddingLoss</li>
</ul>

<p>
&#19981;&#19968;&#19968;&#21015;&#20030;&#65292;&#24635;&#20043;&#65292;&#22914;&#26524;&#26159;&#24819;&#26500;&#24314;&#36215;&#19968;&#20010;&#32593;&#32476;&#65292;&#19981;&#32771;&#34385;&#35757;&#32451;&#30340;&#35805;&#65292;&#37027;&#20040;&#21482;&#29992; torch.nn &#36825;&#20010;&#27169;&#22359;&#37324;&#30340;&#19996;&#35199;&#23601;&#36275;&#22815;&#20102;&#12290;
</p>

<p>
&#27604;&#36739;&#37325;&#35201;&#30340;&#26159; torch.nn.Module &#36825;&#20010;&#31867;&#65292;&#19978;&#36848;&#30340;&#32593;&#32476;&#32467;&#26500;&#12289;&#28608;&#27963;&#20989;&#25968;&#12289;&#30446;&#26631;&#20989;&#25968;&#37117;&#32487;&#25215;&#33258;&#36825;&#20010;&#31867;&#65292;&#22914;&#26524;&#26159;&#24819;&#33258;&#23450;&#20041;&#27169;&#22411;&#12289;&#28608;&#27963;&#20989;&#25968;&#12289;&#30446;&#26631;&#20989;&#25968;&#30340;&#35805;&#65292;&#32487;&#25215;&#36825;&#20010;&#31867;&#23601;&#22909;&#12290;&#25152;&#20197;&#36825;&#20010;&#31867;&#30340;&#34892;&#20026;&#21644;&#20869;&#22312;&#26426;&#21046;&#26377;&#24517;&#35201;&#22909;&#22909;&#20102;&#35299;&#19968;&#19979;&#12290;
</p>

<p>
&#20854;&#27425;&#23601;&#26159; torch.autograd &#36825;&#20010;&#27169;&#22359;&#65292;&#20854;&#20013;&#30340; Variable &#26159; torch &#37324;&#30340;&#36755;&#20837;&#12289;&#36755;&#20986;&#25968;&#25454;&#30340;&#26631;&#20934;&#31867;&#22411;&#65292;&#20063;&#23601;&#26159;&#35828;&#65292;&#25105;&#20204;&#23450;&#20041;&#22909;&#19968;&#20010;&#27169;&#22411;&#21518;&#65292;&#22914;&#26524;&#24819;&#36755;&#20837;&#19996;&#35199;&#65292;&#23601;&#24471;&#25226;&#25968;&#25454;&#37117;&#36716;&#25104; Variable &#31867;&#22411;&#30340;&#20540;&#12290;
</p>

<p>
torch.optim &#37324;&#21017;&#23450;&#20041;&#20102;&#24120;&#29992;&#30340;&#19968;&#20123;&#20248;&#21270;&#26041;&#27861;&#65292;&#19981;&#22810;&#65292;&#32599;&#21015;&#22914;&#19979;
</p>
<ul>
<li>Adadelta</li>
<li>Adagrad</li>
<li>Adam</li>
<li>SparseAdam</li>
<li>Adamax</li>
<li>ASGD</li>
<li>SGD</li>
<li>Rprop</li>
<li>RMSprop</li>
<li>Optimizer</li>
<li>LBFGS</li>
</ul>

<p>
&#24046;&#19981;&#22810;&#23601;&#26159;&#36825;&#20010;&#26679;&#23376;&#12290;
</p>
</div>
</div>

<div>
<h2>&#20854;&#20182;</h2>
<div>
<p>
&#26242;&#26102;&#20102;&#35299;&#36824;&#19981;&#22810;&#65292;&#23601;&#19981;&#38271;&#31687;&#22823;&#35770;&#20102;&#65292;&#36825;&#37324;&#38543;&#20415;&#20889;&#20889;&#12290;
</p>

<p>
&#22312;&#27169;&#22411;&#23618;&#38754;&#65292;pytorch &#20351;&#29992;&#36215;&#26469;&#30830;&#23454;&#33298;&#26381;&#24456;&#22810;&#12290;&#20027;&#35201;&#30340;&#28857;&#26377;&#36825;&#20123;
</p>
<ul>
<li>&#19981;&#38656;&#35201;&#31649; session&#12289;graph &#36825;&#20123;&#19996;&#35199;&#65292;&#23450;&#20041;&#22909;&#30340;&#32593;&#32476;&#32467;&#26500;&#65292;&#30452;&#25509;&#23601;&#33021;&#25509;&#21463;&#36755;&#20837;&#24182;&#24471;&#21040;&#36755;&#20986;</li>
<li>&#27169;&#22359;&#37117;&#32487;&#25215;&#33258; torch.nn.Module &#36825;&#20010;&#31867;&#65292;&#32780;&#36825;&#20010;&#31867;&#34987;&#35774;&#35745;&#25104;&#20102; picklable &#30340;&#65292;&#25105;&#20204;&#30452;&#25509;&#29992; pickle.dump &#21644; pickle.load &#23601;&#33021;&#23545;&#27169;&#22411;&#36827;&#34892;&#20445;&#23384;&#21644;&#21152;&#36733;&#65292;&#30456;&#27604;&#20043;&#19979;&#65292;tensorflow &#40664;&#35748;&#23558;&#27169;&#22411;&#25286;&#25104;&#33509;&#24178;&#20010;&#25991;&#20214;&#28982;&#21518;&#36890;&#36807; saver &#30340;&#26041;&#24335;&#26469;&#20445;&#23384;&#21644;&#21152;&#36733;&#19968;&#30452;&#35753;&#25105;&#38750;&#24120;&#25239;&#25298; &mdash;&mdash; &#20498;&#19981;&#26159;&#35828;&#25105;&#35748;&#20026;&#27169;&#22411;&#23384;&#25104;&#22810;&#20010;&#25991;&#20214;&#23601;&#19981;&#22909;&#65292;&#20294;&#33267;&#23569;&#25552;&#20379;&#35753;&#25105;&#19981;&#23384;&#25104;&#22810;&#20010;&#25991;&#20214;&#30340;&#36873;&#39033;&#21543;&#65311;&#22312; tensorflow &#37324;&#24819;&#35201;&#33258;&#24049;&#21435;&#25226;&#27169;&#22411;&#32467;&#26500;&#21644;&#27169;&#22411;&#21442;&#25968;&#25343;&#20986;&#26469;&#25353;&#33258;&#24049;&#30340;&#24819;&#27861;&#23384;&#20648;&#36825;&#20214;&#20107;&#24773;&#65292;&#25105;&#26159;&#19968;&#30452;&#37117;&#27809;&#26377;&#25104;&#21151;&#36807;&hellip;&hellip;</li>
<li><p>
torch.nn.Module &#31867;&#26377;&#19968;&#20010; bool &#31867;&#22411;&#30340; training &#25104;&#21592;&#65292;&#22914;&#26524;&#23558;&#20854;&#35774;&#32622;&#25104; False&#65292;&#37027;&#20040; Dropout&#12289;BatchNorm &#20043;&#31867;&#30340;&#23618;&#23601;&#20250;&#22833;&#25928;&#65292;&#36825;&#20010;&#34429;&#28982;&#26159;&#20010;&#24456;&#23567;&#30340;&#28857;&#20294;&#20063;&#26159;&#38750;&#24120;&#35753;&#20154;&#33298;&#26381;&#30340;&#19968;&#28857;&#65292;tensorflow &#37324;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#36890;&#24120;&#23601;&#24471;&#33258;&#24049;&#26469;&#35774;&#32622;&#36873;&#39033;&#26469;&#20445;&#35777;&#22312;&#35757;&#32451;&#21644;&#39044;&#27979;&#30340;&#26102;&#20505;&#20135;&#29983;&#20004;&#24352;&#19981;&#21516;&#30340;&#22270;&#65292;&#36156;&#24694;&#24515;
</p>

<p>
&#35814;&#24773;&#35265; <a href="https://discuss.pytorch.org/t/what-does-nn-modules-train-true-train-false-do/4004" rel="noopener noreferrer" target="_blank">&#36825;&#20010;&#24086;&#23376;</a> &#21644; <a href="https://discuss.pytorch.org/t/dropout-changing-between-training-mode-and-eval-mode/6833" rel="noopener noreferrer" target="_blank">&#36825;&#20010;&#24086;&#23376;</a>
</p></li>
</ul>

<p>
&#24403;&#28982;&#65292;&#20063;&#26377;&#19968;&#20123;&#22353;&#65292;&#25110;&#32773;&#35828;&#25105;&#35273;&#24471;&#19981;&#22826;&#28385;&#24847;&#30340;&#22320;&#26041;&#21543;
</p>
<ul>
<li>&#30446;&#21069; pypi &#19978;&#30340;&#29256;&#26412;&#33853;&#21518;&#20110;&#23448;&#32593;&#29256;&#26412;&#65292;&#25353;&#29031;&#23448;&#32593;&#19978;&#30340;&#23433;&#35013;&#26041;&#27861;&#35201;&#19979;&#20960;&#30334;&#20806;&#30340;&#19996;&#35199;&hellip;&hellip;&#21520;&#34880;&hellip;&hellip;</li>
<li>&#27809;&#26377;&#23545;&#25972;&#20010;&#39033;&#30446;&#32467;&#26500;&#21644;&#26426;&#21046;&#30340;&#24635;&#20307;&#20171;&#32461;&#65292;&#24403;&#28982;&#65292;&#27605;&#31455;&#29256;&#26412;&#36824;&#22312; 0.3.0&hellip;&hellip;</li>
<li>&#27169;&#22411;&#20869;&#37096;&#30340;&#25968;&#25454;&#31867;&#22411;&#22909;&#20687;&#26377;&#19981;&#19968;&#33268;&#30340;&#22320;&#26041;&#65292;&#25105;&#22312;&#40664;&#35748;&#34892;&#20026;&#19979;&#65292;&#36935;&#21040;&#36807;&#20160;&#20040; DoubleTensor &#30340;&#38169;&#35823;&#65292;&#21487;&#33021;&#21644;&#36825;&#20010; <a href="https://github.com/pytorch/pytorch/issues/1498" rel="noopener noreferrer" target="_blank">issue</a> &#26377;&#20851;</li>
<li>&#38656;&#35201;&#25163;&#21160;&#36873;&#25321;&#26159;&#21542;&#20351;&#29992; CUDA&#65292;&#20294;&#26159;&#25105;&#26126;&#26126;&#30475;&#21040; torch.cuda &#19979;&#26377;&#20010; is_available &#30340;&#26041;&#27861;</li>
<li>RNN &#30340;&#36755;&#20837;&#21644;&#36755;&#20986;&#65292;&#40664;&#35748;&#31532;&#20108;&#20010;&#32500;&#24230;&#26159; batch&#65292;&#22914;&#26524;&#24819;&#35753;&#31532;&#19968;&#20010;&#32500;&#24230;&#34920;&#31034; batch&#65292;&#23601;&#24471;&#25163;&#21160;&#25226; batch_first &#35774;&#32622;&#25104; True&#65292;&#25402;&#22855;&#24618;&#30340;</li>
</ul>
</div>
</div>